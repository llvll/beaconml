{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BeaconML\n",
    "###*Machine learning in action for iBeacon-based advertising*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple demo to show the machine learning in action for iBeacon-based advertising.\n",
    "\n",
    "The source code for this demo is available on [GitHub](https://github.com/llvll/beaconml) \n",
    "\n",
    "This IP[y] Notebook performs a step-by-step execution of *'beacon_test.py'* file with extra comments.\n",
    "\n",
    "To simplify the process of machine learning we're using TinyLearn framework, which wraps around Scikit-Learn and Pandas modules for easier classification tasks. The most optimal ML algorithm and parameters are selected automatically by ClassificationFacade with the help of cross-validation approach using GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is supplied as CSV file, which contains some statistics from a shopping mall, where iBeacons are installed.\n",
    "\n",
    "Every record in CSV defines the parameters for a successful case - visitor has entered a store or clicked on a mobile app's banner / button. \n",
    "\n",
    "Our goal is to predict *'Message Type'* labels according to the supplied parameters - mobile app's context. Such labels will define the content type to be rendered on a smartphone: \n",
    "\n",
    "* Discount\n",
    "* Product Info\n",
    "* Joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mobile Platform Visitor Type iBeacon Proximity Zone Week-end / Holiday?  \\\n",
      "0          Android          New                   Near                 Yes   \n",
      "1          Android     Returned                    Far                 Yes   \n",
      "2              iOS     Frequent                    Far                  No   \n",
      "3          Android          New              Immediate                  No   \n",
      "4              iOS          New                   Near                  No   \n",
      "5              iOS     Returned                   Near                  No   \n",
      "6              iOS     Frequent                   Near                 Yes   \n",
      "7              iOS     Returned              Immediate                 Yes   \n",
      "8          Android          New              Immediate                 Yes   \n",
      "9          Android     Returned              Immediate                  No   \n",
      "10             iOS     Returned                    Far                  No   \n",
      "11             iOS          New                    Far                  No   \n",
      "12         Android          New                   Near                  No   \n",
      "13             iOS     Returned                   Near                  No   \n",
      "14         Android     Returned                   Near                  No   \n",
      "15             iOS     Frequent                   Near                 Yes   \n",
      "16             iOS     Frequent              Immediate                 Yes   \n",
      "17             iOS     Frequent              Immediate                  No   \n",
      "18         Android          New              Immediate                  No   \n",
      "19         Android          New                   Near                  No   \n",
      "20         Android     Returned                   Near                 Yes   \n",
      "21         Android          New                   Near                 Yes   \n",
      "22         Android     Returned                    Far                 Yes   \n",
      "23             iOS     Returned                   Near                  No   \n",
      "24             iOS          New              Immediate                  No   \n",
      "25         Android     Returned              Immediate                  No   \n",
      "26             iOS     Returned              Immediate                 Yes   \n",
      "27             iOS     Frequent                   Near                 Yes   \n",
      "28         Android     Frequent                    Far                 Yes   \n",
      "29         Android     Frequent                    Far                 Yes   \n",
      "30             iOS     Frequent              Immediate                  No   \n",
      "31         Android          New              Immediate                  No   \n",
      "32         Android          New                   Near                  No   \n",
      "33         Android     Returned                   Near                 Yes   \n",
      "34             iOS     Frequent              Immediate                 Yes   \n",
      "35             iOS          New                   Near                  No   \n",
      "36             iOS     Returned                   Near                  No   \n",
      "37             iOS     Frequent                   Near                 Yes   \n",
      "38             iOS     Returned              Immediate                 Yes   \n",
      "39         Android          New              Immediate                 Yes   \n",
      "\n",
      "   Time of the Day Previous Worked? Executed Action  Message Type  \n",
      "0             Noon               No           Click  Product Info  \n",
      "1          Morning               No           Click  Product Info  \n",
      "2             Noon              Yes     Enter Store          Joke  \n",
      "3          Evening               No     Enter Store      Discount  \n",
      "4          Morning               No     Enter Store  Product Info  \n",
      "5             Noon              Yes     Enter Store  Product Info  \n",
      "6          Evening              Yes           Click  Product Info  \n",
      "7          Evening               No     Enter Store      Discount  \n",
      "8          Evening               No           Click  Product Info  \n",
      "9             Noon              Yes           Click      Discount  \n",
      "10         Morning              Yes     Enter Store          Joke  \n",
      "11            Noon               No     Enter Store      Discount  \n",
      "12         Morning               No     Enter Store      Discount  \n",
      "13            Noon              Yes           Click      Discount  \n",
      "14         Morning              Yes           Click      Discount  \n",
      "15         Evening              Yes     Enter Store      Discount  \n",
      "16         Evening               No     Enter Store          Joke  \n",
      "17         Evening               No     Enter Store      Discount  \n",
      "18            Noon               No     Enter Store      Discount  \n",
      "19            Noon               No     Enter Store  Product Info  \n",
      "20            Noon              Yes           Click  Product Info  \n",
      "21         Evening               No           Click  Product Info  \n",
      "22         Evening              Yes           Click          Joke  \n",
      "23         Morning              Yes     Enter Store      Discount  \n",
      "24         Morning               No     Enter Store      Discount  \n",
      "25         Morning               No     Enter Store          Joke  \n",
      "26            Noon               No           Click  Product Info  \n",
      "27            Noon               No           Click  Product Info  \n",
      "28         Morning              Yes     Enter Store      Discount  \n",
      "29         Morning              Yes     Enter Store      Discount  \n",
      "30         Evening               No     Enter Store      Discount  \n",
      "31            Noon               No     Enter Store      Discount  \n",
      "32            Noon               No     Enter Store  Product Info  \n",
      "33            Noon              Yes           Click  Product Info  \n",
      "34         Evening               No     Enter Store          Joke  \n",
      "35         Morning               No     Enter Store  Product Info  \n",
      "36            Noon              Yes     Enter Store  Product Info  \n",
      "37         Evening              Yes           Click  Product Info  \n",
      "38         Evening               No     Enter Store      Discount  \n",
      "39         Evening               No           Click  Product Info  \n"
     ]
    }
   ],
   "source": [
    "# Let's inspect this CSV file\n",
    "import pandas as pd\n",
    "some_data = pd.read_csv(\"../data/beacon_data.csv\", header=0, index_col=None)\n",
    "print(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've loaded CSV file into Pandas DataFrame, which will contain train and test data for our model. \n",
    "\n",
    "Before we will be able to start training we need to encode the strings into numeric values using LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode strings from CSV into numeric values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "\n",
    "for col_name in some_data:\n",
    "    some_data[col_name] = enc.fit_transform(some_data[col_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the DataFrame into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (the last 5 items)\n",
    "train_features, train_labels = some_data.iloc[:-5, :-1], some_data.iloc[:-5, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the model training and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection summary based on GridSearchCV and 5 estimators.\n",
      "Selected estimator 'ExtraTreeClassifier' with 0.714285714286 mean score.\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "Other scores ...\n",
      "Estimator 'RandomForestClassifier' has mean score 0.657142857143\n",
      "Estimator 'LogisticRegression' has mean score 0.628571428571\n",
      "Estimator 'SVC' has mean score 0.657142857143\n",
      "Estimator 'SGDClassifier' has mean score 0.6\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ClassificationFacade, which will use the default list of estimators.\n",
    "# Removing the features with a weight smaller than 0.1.\n",
    "from tinylearn import ClassificationFacade\n",
    "wrk = ClassificationFacade(train_features, \n",
    "                           train_labels, \n",
    "                           default=True, \n",
    "                           cv=3, \n",
    "                           reduce_func=lambda x: x < 0.1)\n",
    "wrk.train()\n",
    "wrk.print_train_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClassificationFacade has selected *'ExtraTreesClassifier'* estimator. Let's do the actual prediction of labels on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted data:\n",
      "['Discount' 'Product Info' 'Product Info' 'Discount' 'Product Info']\n"
     ]
    }
   ],
   "source": [
    "# Predicting and decoding the labels back to strings\n",
    "print(\"\\nPredicted data:\")\n",
    "predicted = wrk.predict(some_data.iloc[-5:, :-1])\n",
    "print(enc.inverse_transform(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty close to the actual labels ... with the following accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual accuracy: 80.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"\\nActual accuracy: \" +\n",
    "      str(np.sum(predicted == some_data.iloc[-5:, -1])/predicted.size*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the internals of TinyLearn and ClassificationFacade specifically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ../tinylearn.py\n",
    "# Copyright (c) 2015, Oleg Puzanov\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "# * Redistributions of source code must retain the above copyright notice,\n",
    "#   this list of conditions and the following disclaimer.\n",
    "#\n",
    "# * Redistributions in binary form must reproduce the above copyright notice,\n",
    "#   this list of conditions and the following disclaimer in the documentation\n",
    "#   and/or other materials provided with the distribution.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "# POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "\"\"\"Helper classes for the basic classification tasks with Scikit-Learn and Pandas.\"\"\"\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import (ExtraTreesClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import (LogisticRegression,\n",
    "                                  SGDClassifier)\n",
    "\n",
    "\n",
    "class FeatureReducer(object):\n",
    "    \"\"\" Removes the features (columns) from the supplied DataFrame according to the function 'reduce_func'.\n",
    "\n",
    "        The default use case is about removing the features, which have a very small weight and won't be\n",
    "        useful for classification tasks.\n",
    "\n",
    "        Feature weighting is implemented using ExtraTreesClassifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, df_features, df_targets, reduce_func=None):\n",
    "        self.df_features = df_features\n",
    "        self.df_targets = df_targets\n",
    "        self.reduce_func = reduce_func\n",
    "        self.dropped_cols = []\n",
    "\n",
    "    def reduce(self, n_estimators=10):\n",
    "        total_dropped = 0\n",
    "        self.dropped_cols = []\n",
    "\n",
    "        if self.reduce_func is not None:\n",
    "            clf = ExtraTreesClassifier(n_estimators)\n",
    "            clf.fit(self.df_features, self.df_targets).transform(self.df_features)\n",
    "\n",
    "            for i in range(len(clf.feature_importances_)):\n",
    "                if self.reduce_func(clf.feature_importances_[i]):\n",
    "                    total_dropped += 1\n",
    "                    logging.info(\"FeatureReducer: dropping column \\'\" + self.df_features.columns.values[i] + \"\\'\")\n",
    "                    self.dropped_cols.append(self.df_features.columns[i])\n",
    "\n",
    "            [self.df_features.drop(c, axis=1, inplace=True) for c in self.dropped_cols]\n",
    "        return total_dropped\n",
    "\n",
    "    def print_weights(self, n_estimators=10):\n",
    "        clf = ExtraTreesClassifier(n_estimators)\n",
    "        clf.fit(self.df_features, self.df_targets).transform(self.df_features)\n",
    "        [print(\"Feature \\'\" + self.df_features.columns.values[i] +\n",
    "               \" has weight \" + clf.feature_importances_[i]) for i in range(len(clf.feature_importances_))]\n",
    "\n",
    "\n",
    "class CrossValidator(object):\n",
    "    \"\"\" Thin wrapper around 'cross_val_score' method of Scikit-Learn.\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator, df_features, df_targets, cv=5):\n",
    "        self.scores = np.empty\n",
    "        self.estimator = estimator\n",
    "        self.df_features = df_features\n",
    "        self.df_targets = df_targets\n",
    "        self.cv = cv\n",
    "\n",
    "    def cross_validate(self):\n",
    "        self.scores = cross_val_score(self.estimator, self.df_features, self.df_targets, cv=self.cv)\n",
    "        return self.scores\n",
    "\n",
    "    def print_summary(self):\n",
    "        if self.scores.size == 0:\n",
    "            print(\"No data, please execute 'cross_validate' at first.\")\n",
    "        else:\n",
    "            print(\"Cross-validation summary for \" + self.estimator.__class__.__name__)\n",
    "            print(\"Mean score: %0.2f (+/- %0.2f)\" % (self.scores.mean(), self.scores.std() * 2))\n",
    "            [print(\"Score #\" + i + \": %0.2f\", self.scores[i]) for i in range(len(self.scores))]\n",
    "\n",
    "\n",
    "class CvEstimatorSelector(object):\n",
    "    \"\"\"Executes the cross-validation procedures to discover the best performing estimator from the supplied ones.\n",
    "\n",
    "       The best estimator is selected according to the highest mean score.\n",
    "    \"\"\"\n",
    "    def __init__(self, df_features, df_targets, cv=5):\n",
    "        self.scores = {}\n",
    "        self.estimators = {}\n",
    "        self.df_features = df_features\n",
    "        self.df_targets = df_targets\n",
    "        self.cv = cv\n",
    "        self.selected_name = None\n",
    "\n",
    "    def add_estimator(self, name, instance):\n",
    "        self.estimators[name] = instance\n",
    "\n",
    "    def select_estimator(self):\n",
    "        self.selected_name = None\n",
    "        largest_val = 0\n",
    "\n",
    "        for name in self.estimators:\n",
    "            c_val = CrossValidator(self.estimators[name], self.df_features, self.df_targets, self.cv)\n",
    "            self.scores[name] = c_val.cross_validate().mean()\n",
    "            logging.info(\"Mean score for \\'\" + name + \"\\' estimator is \" + str(self.scores[name]))\n",
    "            if largest_val < self.scores[name]:\n",
    "                largest_val = self.scores[name]\n",
    "                self.selected_name = name\n",
    "\n",
    "        return self.selected_name\n",
    "\n",
    "    def print_summary(self):\n",
    "        if self.selected_name is None:\n",
    "            print(\"No data, please execute 'select_estimator' at first.\")\n",
    "        else:\n",
    "            print(\"Selection summary based on the cross-validation of \" +\n",
    "                  str(len(self.estimators)) + \" estimators.\")\n",
    "            print(\"Selected estimator \\'\" + self.selected_name +\n",
    "                  \"\\' with \" + str(self.scores[self.selected_name]) + \" mean score.\")\n",
    "            print(\"Other scores ...\")\n",
    "            [print(\"Estimator \\'\" + n + \" \\' has mean score \" +\n",
    "                   str(self.scores[n])) for n in self.estimators if (n != self.selected_name)]\n",
    "\n",
    "\n",
    "class GridSearchEstimatorSelector(object):\n",
    "    \"\"\"Thin wrapper around GridSearchCV class of Scikit-Learn for discovering the best performing estimator.\n",
    "    \"\"\"\n",
    "    def __init__(self, df_features, df_targets, cv=5):\n",
    "        self.scores = {}\n",
    "        self.estimators = {}\n",
    "        self.df_features = df_features\n",
    "        self.df_targets = df_targets\n",
    "        self.cv = cv\n",
    "        self.selected_name = None\n",
    "        self.best_estimator = None\n",
    "\n",
    "    def add_estimator(self, name, instance, params):\n",
    "        self.estimators[name] = {'instance': instance, 'params': params}\n",
    "\n",
    "    def select_estimator(self):\n",
    "        self.selected_name = None\n",
    "        largest_val = 0\n",
    "\n",
    "        for name in self.estimators:\n",
    "            est = self.estimators[name]\n",
    "            clf = GridSearchCV(est['instance'], est['params'], cv=self.cv)\n",
    "            clf.fit(self.df_features, self.df_targets)\n",
    "            self.scores[name] = clf.best_score_\n",
    "            logging.info(\"Best score for \\'\" + name + \"\\' estimator is \" + str(clf.best_score_))\n",
    "            if largest_val < self.scores[name]:\n",
    "                largest_val = self.scores[name]\n",
    "                self.selected_name = name\n",
    "                self.best_estimator = clf.best_estimator_\n",
    "\n",
    "        return self.selected_name\n",
    "\n",
    "    def print_summary(self):\n",
    "        if self.selected_name is None:\n",
    "            print(\"No data, please execute 'select_estimator' at first.\")\n",
    "        else:\n",
    "            print(\"Selection summary based on GridSearchCV and \" +\n",
    "                  str(len(self.estimators)) + \" estimators.\")\n",
    "            print(\"Selected estimator \\'\" + self.selected_name +\n",
    "                  \"\\' with \" + str(self.scores[self.selected_name]) + \" mean score.\")\n",
    "            print(self.best_estimator)\n",
    "            print(\"\\nOther scores ...\")\n",
    "            [print(\"Estimator \\'\" + n + \"\\' has mean score \" +\n",
    "                   str(self.scores[n])) for n in self.estimators.keys() if (n != self.selected_name)]\n",
    "\n",
    "\n",
    "class ClassificationFacade(object):\n",
    "    \"\"\"Helper class to execute the whole classification workflow - from training to prediction to metrics reporting.\n",
    "\n",
    "       Includes the default list of estimators with instances and parameters, which have been proven to work well.\n",
    "    \"\"\"\n",
    "    def __init__(self, df_features, df_targets, default=True, cv=5, reduce_func=None):\n",
    "        if default:\n",
    "            self.grid_search = GridSearchEstimatorSelector(df_features, df_targets, cv)\n",
    "            self.grid_search.add_estimator('SVC', SVC(), {'kernel': [\"linear\", \"rbf\"],\n",
    "                                                      'C': [1, 5, 10, 50], 'gamma': [0.0, 0.001, 0.0001]})\n",
    "            self.grid_search.add_estimator('RandomForestClassifier', RandomForestClassifier(),\n",
    "                                       {'n_estimators': [5, 10, 20, 50]})\n",
    "            self.grid_search.add_estimator('ExtraTreeClassifier', ExtraTreesClassifier(),\n",
    "                                       {'n_estimators': [5, 10, 20, 50]})\n",
    "            self.grid_search.add_estimator('LogisticRegression', LogisticRegression(),\n",
    "                                       {'C': [1, 5, 10, 50], 'solver': [\"lbfgs\", \"liblinear\"]})\n",
    "            self.grid_search.add_estimator('SGDClassifier', SGDClassifier(),\n",
    "                                       {'n_iter': [5, 10, 20, 50], 'loss': [\"squared_hinge\", \"perceptron\",\n",
    "                                                                            \"hinge\", \"huber\"]})\n",
    "        self.reduce_func = reduce_func\n",
    "        if reduce_func is not None:\n",
    "            self.reducer = FeatureReducer(df_features, df_targets, reduce_func)\n",
    "            self.reducer.reduce(10)\n",
    "\n",
    "    def add_estimator(self, name, instance, params):\n",
    "        self.grid_search.add_estimator(name, instance, params)\n",
    "\n",
    "    def train(self):\n",
    "        return self.grid_search.select_estimator()\n",
    "\n",
    "    def print_train_summary(self):\n",
    "        return self.grid_search.print_summary()\n",
    "\n",
    "    def predict(self, df_data):\n",
    "        if self.grid_search.selected_name is not None:\n",
    "            if self.reduce_func is not None and len(self.reducer.dropped_cols) > 0:\n",
    "                df_data.drop(self.reducer.dropped_cols, axis=1, inplace=True)\n",
    "            return self.grid_search.best_estimator.predict(df_data)\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
